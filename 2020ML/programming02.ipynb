{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание №2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Булатов Айдар Салаватович\n",
    "\n",
    "вуз: МГУ \n",
    "\n",
    "факультет: механико-математический\n",
    "\n",
    "курс: 5\n",
    "\n",
    "кафедра (если есть): механики композитов\n",
    "\n",
    "научный руководитель (если есть): Демидович П.Н."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Данное задание подготовлено с целью ознакомить слушателей с процедурой подготовки данных для алгоритмов машнинного обучения на примере задачи оценки цены недвижимости. Описание данных можно найти в data_description.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Считывание данных (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считайте данные из файлов train.csv и test.csv в массивы:\n",
    "trainX (содержит признаки обучающего множества)\n",
    "trainY (содержит правильные ответа для обучающего множества)\n",
    "testX (содержит признаки для тестового множества)\n",
    "\n",
    "Первый столбец содержит порядковый номер объекта, поэтому его рекомендуется сразу удалить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 79) (1460,) (1459, 79)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\").drop('Id', axis=1)\n",
    "test = pd.read_csv(\"test.csv\").drop('Id', axis=1)\n",
    "\n",
    "trainX = train[train.columns[:-1]].values\n",
    "trainY = train[train.columns[-1]].values\n",
    "testX = test.values\n",
    "\n",
    "print(trainX.shape, trainY.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60 'RL' 65.0 8450 'Pave' nan 'Reg' 'Lvl' 'AllPub' 'Inside' 'Gtl'\n",
      " 'CollgCr' 'Norm' 'Norm' '1Fam' '2Story' 7 5 2003 2003 'Gable' 'CompShg'\n",
      " 'VinylSd' 'VinylSd' 'BrkFace' 196.0 'Gd' 'TA' 'PConc' 'Gd' 'TA' 'No'\n",
      " 'GLQ' 706 'Unf' 0 150 856 'GasA' 'Ex' 'Y' 'SBrkr' 856 854 0 1710 1 0 2 1\n",
      " 3 1 'Gd' 8 'Typ' 0 nan 'Attchd' 2003.0 'RFn' 2 548 'TA' 'TA' 'Y' 0 61 0 0\n",
      " 0 0 nan nan nan 0 2 2008 'WD' 'Normal']\n"
     ]
    }
   ],
   "source": [
    "print(trainX[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Предварительная обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как правило \"реальные\" данные содержат пропущенные значения и прочие нечисловые признаки, поэтому прежде чем запустить методы fit и  predict модели, необходимо сделать все признаки числовыми."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Обработка пропущенных значений (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучите раздел документации https://scikit-learn.org/stable/modules/impute.html#impute и параметры классов SimpleImputer и MissingIndicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import MissingIndicator, SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6965\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "indicator = MissingIndicator()\n",
    "train_mask_missing_values_only = indicator.fit_transform(trainX)\n",
    "test_mask_missing_values_only = indicator.fit_transform(testX)\n",
    "print(np.sum(train_mask_missing_values_only))\n",
    "print(np.sum(test_mask_missing_values_only))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных были обнаружены пропущенные значение. \n",
    "При помощи класса MissingIndicator устраните пропущенные значения, использовав самый часто встречаемый элемент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код\n",
    "imp_mf = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "trainX_without_missing = imp_mf.fit_transform(trainX)# ваш код\n",
    "# imp_mf = SimpleImputer(strategy='most_frequent')\n",
    "testX_without_missing = imp_mf.fit_transform(testX)# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "indicator = MissingIndicator()\n",
    "train_mask_missing_values_only = indicator.fit_transform(trainX_without_missing)\n",
    "test_mask_missing_values_only = indicator.fit_transform(testX_without_missing)\n",
    "print(np.sum(train_mask_missing_values_only))\n",
    "print(np.sum(test_mask_missing_values_only))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропущенные значения удалены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60 'RL' 65.0 8450 'Pave' 'Grvl' 'Reg' 'Lvl' 'AllPub' 'Inside' 'Gtl'\n",
      " 'CollgCr' 'Norm' 'Norm' '1Fam' '2Story' 7 5 2003 2003 'Gable' 'CompShg'\n",
      " 'VinylSd' 'VinylSd' 'BrkFace' 196.0 'Gd' 'TA' 'PConc' 'Gd' 'TA' 'No'\n",
      " 'GLQ' 706 'Unf' 0 150 856 'GasA' 'Ex' 'Y' 'SBrkr' 856 854 0 1710 1 0 2 1\n",
      " 3 1 'Gd' 8 'Typ' 0 'Gd' 'Attchd' 2003.0 'RFn' 2 548 'TA' 'TA' 'Y' 0 61 0\n",
      " 0 0 0 'Gd' 'MnPrv' 'Shed' 0 2 2008 'WD' 'Normal']\n"
     ]
    }
   ],
   "source": [
    "print(trainX_without_missing[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2  Обработка категориальных значений (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучите раздел документации https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features\n",
    "\n",
    "При помощи класса OrdinalEncoder удалите категориальные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 'RH', 80.0, 11622, 'Pave', 'Grvl', 'Reg', 'Lvl', 'AllPub',\n",
       "       'Inside', 'Gtl', 'NAmes', 'Feedr', 'Norm', '1Fam', '1Story', 5, 6,\n",
       "       1961, 1961, 'Gable', 'CompShg', 'VinylSd', 'VinylSd', 'None', 0.0,\n",
       "       'TA', 'TA', 'CBlock', 'TA', 'TA', 'No', 'Rec', 468.0, 'LwQ', 144.0,\n",
       "       270.0, 882.0, 'GasA', 'TA', 'Y', 'SBrkr', 896, 0, 0, 896, 0.0, 0.0,\n",
       "       1, 0, 2, 1, 'TA', 5, 'Typ', 0, 'Gd', 'Attchd', 1961.0, 'Unf', 1.0,\n",
       "       730.0, 'TA', 'TA', 'Y', 140, 0, 0, 0, 120, 0, 'Ex', 'MnPrv',\n",
       "       'Shed', 0, 6, 2010, 'WD', 'Normal'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX_without_missing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ваш код\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "\n",
    "trainX_without_missing_and_cat = enc.fit_transform(trainX_without_missing)#ваш код\n",
    "testX_without_missing_and_cat = enc.fit_transform(testX_without_missing)# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.   3.  36. 327.   1.   0.   3.   3.   0.   4.   0.   5.   2.   2.\n",
      "   0.   5.   6.   4. 104.  53.   1.   1.  12.  13.   1. 128.   2.   4.\n",
      "   2.   2.   3.   3.   2. 361.   5.   0.  73. 179.   1.   0.   1.   4.\n",
      " 134. 232.   0. 531.   1.   0.   2.   1.   3.   1.   2.   6.   6.   0.\n",
      "   2.   1.  89.   1.   2. 220.   4.   4.   2.   0.  49.   0.   0.   0.\n",
      "   0.   2.   2.   2.   0.   1.   2.   8.   4.]\n"
     ]
    }
   ],
   "source": [
    "print(trainX_without_missing_and_cat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь данные готовы для обучения моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишите достоинства и недостатки данного метода обработки категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "достоинства:\n",
    "- не так сильно растет размерность в случае большого числа категорий\n",
    "\n",
    "недостатки:\n",
    "- добавляем шумовую информацию\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Разделение данных на обучение и валидацию (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите обучающее множество на обучение(75%) и валидацию(25%), воспользовавшись функцией train_test_split с random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(trainX_without_missing_and_cat,\n",
    "                                                  trainY,\n",
    "                                                  train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 79) (365, 79) (1095,) (365,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Обучение моделей (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные готовы для обучения алгоритмов машинного обучения. В качестве базовой можеди возьмём линейную регрессию, меткрика качества - mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3817497024775967\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_val)\n",
    "y_pred[y_pred < 0.0] = 0.0\n",
    "\n",
    "print(mean_squared_log_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текущую модель можно существенно улучшить. Добейтесь на валидации ошибки меньше 0.03 без каких-либо ограничений на алгоритмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02059500420904404\n"
     ]
    }
   ],
   "source": [
    "# model = Lasso()\n",
    "# model = LogisticRegression()\n",
    "# model = KNeighborsRegressor()\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred[y_pred < 0.0] = 0.0\n",
    "\n",
    "print(mean_squared_log_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лучший результат дала регрессия случайным лесом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Способы улучшения качества модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Применить другую стратегию обработки пропущенных значений из scikit-learn (1 балл + 1 балл, если получили прирост качества для алгоритма с ошибкой меньше 0.03 )\n",
    "\n",
    "2. Добавить бинарные признаки отсутствия/присутствия значения для столбцов, где есть пропущенные значения (1 балл)\n",
    "\n",
    "3. Реализовать самостоятельно одну из стратегий обработки пропущенных значений из семинара (начиная с kNN) (2 балла)\n",
    "\n",
    "4. Применить стратегию OneHotEncoder  для обработки категориальных признаков (2 балла)\n",
    "\n",
    "5. Применить стратегию агрегированния данных для обработки категориальных признаков (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте не менее двух идей из предложенных выше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Попробуем IterativeImputer и KNNImputer. Для категориальных признаков используем SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = []\n",
    "numerical = []\n",
    "trainY = train[train.columns[-1]]\n",
    "\n",
    "for col in train.columns[:-1]:\n",
    "    for val in train[col]:\n",
    "        if str(val) == val and not col in categorical:\n",
    "            categorical.append(col)\n",
    "            \n",
    "    if col not in categorical:\n",
    "        numerical.append(col)\n",
    "        \n",
    "train_cat = train[categorical]\n",
    "train_num = train[numerical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "\n",
    "# num_imp = IterativeImputer()\n",
    "# num_imp = SimpleImputer(strategy='mean')\n",
    "num_imp = KNNImputer()\n",
    "cat_imp = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "train_num = num_imp.fit_transform(train_num)\n",
    "train_cat = cat_imp.fit_transform(train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_smart_imput = np.hstack([train_num, train_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0204700659025712\n"
     ]
    }
   ],
   "source": [
    "enc = OrdinalEncoder()\n",
    "trainX_smart_imput_nocat = enc.fit_transform(trainX_smart_imput)\n",
    "\n",
    "X_train_smart_imput, X_val_smart_imput, y_train_smart_imput, y_val_smart_imput = train_test_split(trainX_smart_imput_nocat,\n",
    "                                                  trainY,\n",
    "                                                  train_size=0.75, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train_smart_imput, y_train_smart_imput)\n",
    "y_pred = model.predict(X_val_smart_imput)\n",
    "y_pred[y_pred < 0.0] = 0.0\n",
    "\n",
    "print(mean_squared_log_error(y_val_smart_imput, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "точность с обработкой пропусков 0.856511144079803\n"
     ]
    }
   ],
   "source": [
    "print(\"точность с обработкой пропусков\", \\\n",
    "      cross_val_score(model, trainX_smart_imput_nocat, trainY, cv=3).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Добавим бинарные признаки отсутствия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indicated = train.copy()\n",
    "test_indicated = test.copy()\n",
    "\n",
    "ind = MissingIndicator()\n",
    "indicator_columns = ind.fit_transform(train_indicated)\n",
    "for i, col in enumerate(indicator_columns.T):\n",
    "    train_indicated[str(i)] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00042119565329856994\n"
     ]
    }
   ],
   "source": [
    "trainX_indicated = train_indicated[train_indicated.columns[:-1]].values\n",
    "\n",
    "imp_mf = SimpleImputer(strategy='most_frequent')\n",
    "trainX_without_missing_indicated = imp_mf.fit_transform(trainX_indicated)\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "trainX_without_missing_and_cat_indicated = enc.fit_transform(trainX_without_missing_indicated)\n",
    "\n",
    "X_train_indicated, X_val_indicated, y_train_indicated, y_val_indicated = train_test_split(trainX_without_missing_and_cat_indicated,\n",
    "                                                  trainY,\n",
    "                                                  train_size=0.75, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train_indicated, y_train_indicated)\n",
    "y_pred = model.predict(X_val_indicated)\n",
    "y_pred[y_pred < 0.0] = 0.0\n",
    "\n",
    "print(mean_squared_log_error(y_val_indicated, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "точность с индикаторами отсутствия:  0.855113356372537\n"
     ]
    }
   ],
   "source": [
    "print(\"точность с индикаторами отсутствия: \", \\\n",
    "      cross_val_score(model, trainX_without_missing_and_cat, trainY, cv=3).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHotEncoder сильно увеличивает размерность и время работы, не уменьшая ошибку. Точность на кросс-валидации меньше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "trainX_without_missing_and_cat_onehot = enc.fit_transform(trainX_without_missing)\n",
    "\n",
    "X_train_onehot, X_val_onehot, y_train_onehot, y_val_onehot = train_test_split(trainX_without_missing_and_cat_onehot,\n",
    "                                                  trainY,\n",
    "                                                  train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03484946154427984\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "model.fit(X_train_onehot, y_train)\n",
    "y_pred = model.predict(X_val_onehot)\n",
    "y_pred[y_pred < 0.0] = 0.0\n",
    "\n",
    "print(mean_squared_log_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "точность с OneHotEncoder 0.7721093642298994\n"
     ]
    }
   ],
   "source": [
    "print(\"точность с OneHotEncoder\", \\\n",
    "      cross_val_score(model, trainX_without_missing_and_cat_onehot, trainY, cv=3).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
